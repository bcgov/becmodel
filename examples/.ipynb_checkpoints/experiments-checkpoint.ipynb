{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-23 11:42:30,508 becmodel.main INFO     Initializing BEC model v0.0.3dev\n",
      "2019-07-23 11:42:30,509 becmodel.util INFO     Loading config from file: /Users/snorris/projects/geobc/bec_modernization/becmodel/tests/test.cfg\n"
     ]
    },
    {
     "ename": "ConfigValueError",
     "evalue": "config rulepolys_file: tests/data/data.gdb.zip does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a59174fbc535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/snorris/projects/geobc/bec_modernization/becmodel/tests/test.cfg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mBM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBECModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mBM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mBM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_elevation_merges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/geobc/bec_modernization/becmodel/becmodel/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config_file)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing BEC model v{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbecmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/geobc/bec_modernization/becmodel/becmodel/util.py\u001b[0m in \u001b[0;36mload_config\u001b[0;34m(config_file)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mvalidate_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/geobc/bec_modernization/becmodel/becmodel/util.py\u001b[0m in \u001b[0;36mvalidate_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             raise ConfigValueError(\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;34m\"config {}: {} does not exist\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             )\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigValueError\u001b[0m: config rulepolys_file: tests/data/data.gdb.zip does not exist"
     ]
    }
   ],
   "source": [
    "import becmodel\n",
    "from becmodel import util\n",
    "from becmodel import BECModel\n",
    "\n",
    "\n",
    "# load and process default (test) data\n",
    "#config_file = \"/Users/snorris/projects/geobc/bec_modernization/test_projects/robson/robson_config.cfg\"\n",
    "config_file = \"/Users/snorris/projects/geobc/bec_modernization/becmodel/tests/test.cfg\"\n",
    "\n",
    "BM = BECModel(config_file=config_file)\n",
    "BM.validate()\n",
    "BM.high_elevation_merges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpine': [1], 'parkland': [2, 10], 'woodland': [11, 3], 'high': [4, 12]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM.high_elevation_dissolves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaps = [\n",
    "    {\"rule\": 123,\n",
    "    \"type\": \"alpine\",\n",
    "    \"becvalue\": 1,\n",
    "    \"becvalue_target\": 2\n",
    "    },\n",
    "    {\"rule\": 123,\n",
    "    \"type\": \"parkland\",\n",
    "    \"becvalue\": 2,\n",
    "    \"becvalue_target\": 3\n",
    "    },\n",
    "    {\"rule\": 123,\n",
    "    \"type\": \"woodland\",\n",
    "    \"becvalue\": 3,\n",
    "    \"becvalue_target\": 4\n",
    "    },\n",
    "    {\"rule\": 126,\n",
    "    \"type\": \"parkland\",\n",
    "    \"becvalue\": 8,\n",
    "    \"becvalue_target\": 9\n",
    "    },\n",
    "    {\"rule\": 126,\n",
    "    \"type\": \"woodland\",\n",
    "    \"becvalue\": 9,\n",
    "    \"becvalue_target\": 10\n",
    "    },\n",
    "\n",
    "    {\"rule\": 124,\n",
    "    \"type\": \"woodland\",\n",
    "    \"becvalue\": 6,\n",
    "    \"becvalue_target\": 7\n",
    "    }\n",
    "\n",
    "]\n",
    "dissolve_lookup = {\n",
    "    \"alpine\": [r[\"becvalue\"] for r in remaps if r[\"type\"] == 'alpine'],\n",
    "    \"parkland\": [r[\"becvalue\"] for r in remaps if r[\"type\"] == 'parkland'],\n",
    "    \"woodland\": [r[\"becvalue\"] for r in remaps if r[\"type\"] == 'woodland'],\n",
    "    \"high\": [r[\"becvalue_target\"] for r in remaps if r[\"type\"] == 'woodland']\n",
    "}\n",
    " \n",
    "dissolve_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "plt.axis('off')\n",
    "plt.imshow(BM.data[\"aspect_class\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data[\"11_dissolvenoise\"].shape[0] > 1:\n",
    "\n",
    "    # label the noise polys\n",
    "    data[\"11_dissolvenoise\"][\"noise\"] = \"noise\"\n",
    "\n",
    "    # Get representative point of the small noise polys so we can easily\n",
    "    # select polys in various dataframes using intersects()\n",
    "    data[\"12_dissolvenoisepts\"] = data[\"11_dissolvenoise\"].copy()\n",
    "    data[\"12_dissolvenoisepts\"][\"geometry\"] = data[\n",
    "        \"12_dissolvenoisepts\"\n",
    "    ].representative_point()\n",
    "\n",
    "    # make a copy the pre-dissolve df with just the needed columns\n",
    "    df1 = data[\"becvalue_1\"].copy().reset_index()\n",
    "    df1 = df1[[\"becvalue\", \"polygon_number\", \"geometry\"]]\n",
    "\n",
    "    # overlay the copy with the sliver/noise points to identify which\n",
    "    # pre-dissolve polys need to be eliminated\n",
    "    data[\"13_toelim\"] = gpd.sjoin(\n",
    "        df1, data[\"12_dissolvenoisepts\"], how=\"left\", op=\"intersects\"\n",
    "    )[[\"becvalue\", \"polygon_number\", \"noise\", \"geometry\"]]\n",
    "\n",
    "    # extract just the noise polygons, reset index and create a new column\n",
    "    # with unique values\n",
    "    df2 = data[\"13_toelim\"][data[\"13_toelim\"][\"noise\"] == \"noise\"].reset_index()\n",
    "    df2[\"id\"] = df2.index\n",
    "\n",
    "    # extract non-noise polys and buffer slightly\n",
    "    df3 = data[\"13_toelim\"][data[\"13_toelim\"] != \"noise\"]\n",
    "    df3[\"geometry\"] = df3.buffer(.01)\n",
    "\n",
    "    # find intersection of noise and buffered non-noise - the intersect\n",
    "    # with the largest area should generally have the longest shared\n",
    "    # edge This seems less prone to precision errors that may occur if\n",
    "    # actually generating shared edges.\n",
    "    df4 = gpd.overlay(df2, df3, how=\"intersection\")\n",
    "    df4[\"area\"] = df4[\"geometry\"].area\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas \n",
    "%matplotlib inline\n",
    "\n",
    "smalls = BM.data[\"becvalue_2\"][BM.data[\"becvalue_2\"][\"geometry\"].area < BM.config[\"noise_removal_threshold\"]]\n",
    "smalls[\"small\"] = 'small'                           \n",
    "smalls = smalls[[\"small\", \"geometry\"]]\n",
    "\n",
    "# get representative point so we can easily select between dataframes using intersects\n",
    "smalls_pts = smalls.copy()\n",
    "smalls_pts[\"geometry\"] = smalls.representative_point()\n",
    "#smalls_pts.plot()\n",
    "\n",
    "# now assign a new becvalue to these small records for elimination, getting the \n",
    "# becvalue from adjacent poly within the same rule polyon with largest shared edge...\n",
    "\n",
    "z = BM.data[\"becvalue_1\"].copy().reset_index()\n",
    "z = z[[\"becvalue\", \"polygon_number\", \"geometry\"]]\n",
    "# find pre-dissolve records that intersect with the features to eliminate (smalls)\n",
    "x = geopandas.sjoin(z, smalls_pts, how=\"left\", op=\"intersects\")[[\"becvalue\", \"polygon_number\", \"small\", \"geometry\"]]\n",
    "\n",
    "# do a self join \n",
    "y = geopandas.sjoin(x, x, how=\"left\", op=\"intersects\")\n",
    "\n",
    "# remove self-intersections and intersections from different rule polys from self-join\n",
    "a = y[(y[\"index_right\"] != y.index) & (y[\"polygon_number_left\"] == y[\"polygon_number_right\"])]\n",
    "b = a[a[\"small_left\"] == \"small\"]\n",
    "#b.index.duplicated()\n",
    "\n",
    "# try self overlay\n",
    "sm = x[x[\"small\"] == \"small\"].reset_index()\n",
    "sm[\"id\"] = sm.index\n",
    "ns = x[x[\"small\"] != \"small\"]\n",
    "ns[\"geometry\"] = ns.buffer(.01)\n",
    "res = geopandas.overlay(sm, ns, how='intersection')\n",
    "res[\"area\"] = res[\"geometry\"].area\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by area to presumably get the longest shared edge\n",
    "df = res[res[\"polygon_number_1\"] == res[\"polygon_number_2\"]]\n",
    "df = df.sort_values(by = ['id',\"area\"], ascending = [True, False])\n",
    "df = df.drop_duplicates(subset='id', keep='first')\n",
    "df[\"geometry\"] = df.representative_point()\n",
    "df = df[[\"becvalue_2\", \"geometry\"]]\n",
    "\n",
    "# join back..\n",
    "out = geopandas.sjoin(z, df, how=\"left\", op=\"intersects\")\n",
    "# update\n",
    "out.loc[out.index_right >= 0, 'becvalue'] = out.becvalue_2\n",
    "\n",
    "# reapply dissolve\n",
    "outdiz = util.multi2single(out\n",
    "    .dissolve(by=\"becvalue\")\n",
    "    .reset_index()[[\"becvalue\", \"geometry\"]]\n",
    ")\n",
    "\n",
    "# tidy the geoms by buffer out, buffer in\n",
    "outdiz[\"geometry\"] = outdiz.buffer(.01)\n",
    "outdiz[\"geometry\"] = outdiz.buffer(-.01)\n",
    "outdiz.to_file(\"bectest.gpkg\", layer='outdiz_bufoutin', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy.ma as ma\n",
    "from rasterio.features import shapes\n",
    "import rasterio\n",
    "import fiona\n",
    "import skimage.morphology\n",
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "from math import ceil\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.features import shapes\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from geojson import Feature, FeatureCollection\n",
    "from skimage.filters.rank import majority\n",
    "import skimage.morphology as morphology\n",
    "import bcdata\n",
    "\n",
    "import becmodel\n",
    "from becmodel import util\n",
    "\n",
    "import mplleaflet\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "    \n",
    "from becmodel import BECModel\n",
    "\n",
    "# load and process default (test) data\n",
    "config_file = \"/Users/snorris/projects/geobc/bec_modernization/test_projects/robson/robson_config.cfg\"\n",
    "BM = BECModel(config_file=config_file)\n",
    "BM.validate()\n",
    "BM.run()\n",
    "BM.write(qa=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for rule_poly in rulepoly_merge_lookup:\n",
    "rule_poly = 122\n",
    "from skimage.morphology import disk\n",
    "from skimage.morphology import dilation\n",
    "\n",
    "# get zero areas within the rule poly     \n",
    "X = np.where(BM.data[\"rules_image\"] == rule_poly,\n",
    "        BM.data[\"becvalue_3_noisefilter\"],\n",
    "        0\n",
    "    )\n",
    "\n",
    "# dilate\n",
    "selem = disk(10)\n",
    "dilated = dilation(X, selem)\n",
    "\n",
    "# get just 0 areas from dilation\n",
    "Y = np.where((BM.data[\"rules_image\"] == rule_poly) &\n",
    "              (BM.data[\"becvalue_3_noisefilter\"] == 0),\n",
    "        dilated,\n",
    "        0\n",
    "    )\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "plt.axis('off')\n",
    "plt.imshow(Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write intermediate layers\n",
    "for l in BM.data[\"rule_bnd_buf\"]:\n",
    "    BM.data[\"rule_bnd_buf\"][l].to_file(\n",
    "        os.path.join(BM.config[\"wksp\"], BM.config[\"out_file\"]),\n",
    "        layer='t'+str(l)+\"_01_buf\",\n",
    "        driver=\"GPKG\",\n",
    "    )\n",
    "    \n",
    "for i, l in enumerate(BM.data[\"becvalue_polys\"]):\n",
    "    BM.data[\"becvalue_polys\"][l].to_file(\n",
    "        os.path.join(BM.config[\"wksp\"], BM.config[\"out_file\"]),\n",
    "        layer='t'+str(l)+\"_02_becvalue\",\n",
    "        driver=\"GPKG\",\n",
    "    )\n",
    "for i, l in enumerate(BM.data[\"becvalue_polys_clipped\"]):\n",
    "    BM.data[\"becvalue_polys_clipped\"][l].to_file(\n",
    "        os.path.join(BM.config[\"wksp\"], BM.config[\"out_file\"]),\n",
    "        layer='t'+str(l)+\"_03_becvalueclip\",\n",
    "        driver=\"GPKG\",\n",
    "    )\n",
    "BM.write(qa=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulepoly_merge_lookup = {}\n",
    "for rule_poly in data[\"rulepolys\"].polygon_number.tolist():\n",
    "    mergerules = BM.get_merge_codes(rule_poly)\n",
    "    if mergerules:\n",
    "        rulepoly_merge_lookup[rule_poly] = mergerules\n",
    "\n",
    "high_elevation_removal_threshold =2500000\n",
    "\n",
    "rule_poly = 122\n",
    "\n",
    "with rasterio.open(os.path.join(BM.config[\"wksp\"], \"dem.tif\")) as src:\n",
    "    shape = src.shape\n",
    "    transform = src.transform\n",
    "            \n",
    "            \n",
    "# get the outline of the rule poly and buffer it\n",
    "BM.data[\"rule_bnd_buf\"][rule_poly] = BM.data[\"rulepolys\"][\n",
    "    BM.data[\"rulepolys\"].polygon_number == rule_poly\n",
    "]\n",
    "BM.data[\"rule_bnd_buf\"][rule_poly][\"geometry\"] = BM.data[\"rule_bnd_buf\"][rule_poly].buffer(2000)\n",
    "data = BM.data\n",
    "# keep only columns of interest\n",
    "data[\"rule_bnd_buf\"][rule_poly] = data[\"rule_bnd_buf\"][rule_poly][[\"polygon_number\", \"geometry\"]]\n",
    "# rasterize the buffered area\n",
    "rule_bnd_image = features.rasterize(\n",
    "    (\n",
    "        (geom, value)\n",
    "        for geom, value in zip(\n",
    "            data[\"rule_bnd_buf\"][rule_poly].geometry, data[\"rule_bnd_buf\"][rule_poly].polygon_number\n",
    "        )\n",
    "    ),\n",
    "    out_shape=shape,\n",
    "    transform=transform,\n",
    "    all_touched=False,\n",
    "    dtype=np.uint16,\n",
    ")\n",
    "\n",
    "# generate output image for rule poly area\n",
    "out_image = np.where(\n",
    "    rule_bnd_image == rule_poly, data[\"becvalue_3_noisefilter\"], 0\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lookup = rulepoly_merge_lookup[rule_poly]\n",
    "print(merge_lookup)\n",
    "\n",
    "# iterate through the merges in order of insertion (Python >=3.6)\n",
    "#for merge_label in merge_lookup:\n",
    "merge_label = 'ESSFwcp'\n",
    "log.info(\n",
    "    \"high_elevation_removal: rule_poly: {}, merge_label:{}\".format(\n",
    "        rule_poly, merge_label\n",
    "    )\n",
    ")\n",
    "\n",
    "# Extract area of interest:\n",
    "# if finding small alpine areas, extract parkland and\n",
    "# remove small holes from the parkland\n",
    "X = np.where(\n",
    "    out_image == BM.becvalue_lookup[merge_lookup[merge_label]],\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "\n",
    "# remove small holes from parkland/woodland/high\n",
    "Y = morphology.remove_small_holes(X, high_elevation_removal_threshold)\n",
    "\n",
    "# apply the removed holes to output image where value\n",
    "# corresponds to value to be removed (ie, alpine for parkland)\n",
    "out_image = np.where(\n",
    "    (Y == 1) & (out_image == BM.becvalue_lookup[merge_label]),\n",
    "    BM.becvalue_lookup[merge_lookup[merge_label]],\n",
    "    out_image,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "plt.axis('off')\n",
    "plt.imshow(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BM.beclabel_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to polygon feature collection and load to a data frame\n",
    "fc = FeatureCollection(\n",
    "    [\n",
    "        Feature(geometry=s, properties={\"becvalue\": v})\n",
    "        for i, (s, v) in enumerate(shapes(out_image, transform=transform))\n",
    "    ]\n",
    ")\n",
    "#data[\"becvalue_polys\"][rule_poly] = gpd.GeoDataFrame.from_features(fc)\n",
    "#fc\n",
    "#data[\"rulepolys\"][data[\"rulepolys\"].polygon_number == 122].plot()\n",
    "data[\"becvalue_polys_clipped\"][122].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to original rule poly bnd\n",
    "data[\"becvalue_polys_clipped\"][rule_poly] = gpd.overlay(\n",
    "    data[\"becvalue_polys\"][rule_poly],\n",
    "    self.data[\"rulepolys\"][\n",
    "        self.data[\"rulepolys\"].polygon_number == rule_poly\n",
    "    ],\n",
    "    how=\"intersection\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplleaflet\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15.0, 10.0) \n",
    "\n",
    "#filename = '/Users/snorris/projects/geobc/bec_modernization/becmodel/tests/data/data.gdb'\n",
    "#filename = '/Users/snorris/projects/geobc/bec_modernization/test_projects/robson/becmodel_tempdata/becmodel.gpkg'\n",
    "#p = gpd.read_file(filename, layer=\"becvalue\")\n",
    "#p.crs ={'init' :'epsg:3005'}\n",
    "ax = BM.data[\"rulepolys\"].plot()\n",
    "#ax = p.plot()\n",
    "mplleaflet.display(fig=ax.figure, crs={'init' :'epsg:3005'}, tiles='esri_worldtopo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find outputs < noise threshold\n",
    "BM.data[\"becvalue_1\"][BM.data[\"becvalue_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view rules polygons\n",
    "BM.data[\"rulepolys\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view rules data\n",
    "BM.data[\"rulepolys\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view elevation table\n",
    "BM.data[\"elevation\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model \n",
    "# (get DEM, process, generate outputs in memory)\n",
    "BM.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM.data[\"becvalue_concat_diz\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view DEM\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.patch.set_alpha(0)\n",
    "plt.imshow(BM.data[\"dem\"], cmap='cubehelix', zorder=1)\n",
    "plt.colorbar(label='Elevation (m)')\n",
    "plt.title('DEM')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view aspect, aspect class\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(BM.data[\"aspect\"])\n",
    "ax[1].imshow(BM.data[\"aspect_class\"])\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot output raster\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(BM.data[\"becvalue_4_highelevationfilter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# High elevation noise removal\n",
    "# ----------------------------------------------------------------\n",
    "# convert high_elevation_removal_threshold value from m2 to n cells\n",
    "high_elevation_removal_threshold = int(\n",
    "    BM.config[\"high_elevation_removal_threshold\"]\n",
    "    / (BM.config[\"cell_size\"] ** 2)\n",
    ")\n",
    "\n",
    "x = BM.data[\"becvalue_3_noisefilter\"].copy()\n",
    "\n",
    "rulepoly_merge_lookup = {}\n",
    "for rule_poly in BM.data[\"rulepolys\"].polygon_number.tolist():\n",
    "    mergerules = BM.get_merge_codes(rule_poly)\n",
    "    if mergerules:\n",
    "        rulepoly_merge_lookup[rule_poly] = mergerules\n",
    "rulepoly_merge_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for rule_poly in rulepoly_merge_lookup:\n",
    "#    print(rule_poly)\n",
    "    # get the source polygon and buffer\n",
    "rule_poly = 123\n",
    "rp = BM.data[\"rulepolys\"][BM.data[\"rulepolys\"].polygon_number == rule_poly]\n",
    "rp_buff = BM.data[\"rulepolys\"][BM.data[\"rulepolys\"].polygon_number == rule_poly]\n",
    "rp.plot()\n",
    "rp_buff[\"geometry\"] = rp.buffer(1000)\n",
    "rp_buff.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(os.path.join(BM.config[\"wksp\"], \"dem.tif\")) as src:\n",
    "    shape = src.shape\n",
    "    transform = src.transform\n",
    "    \n",
    "rule_poly_df = BM.data[\"rulepolys\"][BM.data[\"rulepolys\"].polygon_number == rule_poly]\n",
    "rule_poly_df[\"geometry\"] = rule_poly_df.buffer(2000)\n",
    "rule_poly_image = features.rasterize(\n",
    "    (\n",
    "        (geom, value)\n",
    "        for geom, value in zip(\n",
    "            rule_poly_df.geometry, rule_poly_df.polygon_number\n",
    "        )\n",
    "    ),\n",
    "    out_shape=shape,\n",
    "    transform=transform,\n",
    "    all_touched=False,\n",
    "    dtype=np.uint16,\n",
    ")\n",
    "# plot output raster\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(rule_poly_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BM.data[\"becvalue_4_highelevationfilter\"] = BM.data[\"becvalue_3_noisefilter\"].copy()\n",
    "\n",
    "out = np.where(\n",
    "        rule_poly_image == rule_poly,\n",
    "        BM.data[\"becvalue_3_noisefilter\"],\n",
    "        0,\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lookup = rulepoly_merge_lookup[rule_poly]\n",
    "# iterate through the merges in order of insertion (Python >=3.6)\n",
    "for merge_label in merge_lookup:\n",
    "\n",
    "    # Extract area of interest:\n",
    "    # if finding small alpine areas, extract parkland and\n",
    "    # remove small holes from the parkland\n",
    "    X = np.where(\n",
    "        (rule_poly_image == rule_poly)\n",
    "        & (\n",
    "            BM.data[\"becvalue_4_highelevationfilter\"]\n",
    "            == BM.becvalue_lookup[merge_lookup[merge_label]]\n",
    "        ),\n",
    "        1,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    # remove small holes from parkland/woodland/high\n",
    "    Y = morphology.remove_small_holes(X, high_elevation_removal_threshold)\n",
    "\n",
    "    # apply the removed holes to out image where value\n",
    "    # corresponds to value to be removed (ie, alpine for parkland)\n",
    "    out = np.where(\n",
    "        (Y == 1)\n",
    "        & (\n",
    "            out == BM.becvalue_lookup[merge_label]\n",
    "        ),\n",
    "        BM.becvalue_lookup[merge_lookup[merge_label]],\n",
    "        out,\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FeatureCollection(\n",
    "    [\n",
    "        Feature(geometry=s, properties={\"becvalue\": v})\n",
    "        for i, (s, v) in enumerate(\n",
    "            shapes(out, transform=transform) \n",
    "        )\n",
    "    ]\n",
    ")\n",
    "r = gpd.GeoDataFrame.from_features(fc)\n",
    "# remove zeros\n",
    "r2 = r[r.becvalue != 0]\n",
    "r2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip by rule poly\n",
    "r3 = gpd.overlay(r2, BM.data[\"rulepolys\"][BM.data[\"rulepolys\"].polygon_number == rule_poly], how='intersection') \n",
    "r3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find intersection of buffered rule poly and existing beczone polys\n",
    "clipped = gpd.overlay(BM.data[\"polys\"], clip_poly, how='intersection') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to poly, join back to elevation table to identify alpine / parkland\n",
    "\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "from rasterio.features import shapes\n",
    "import rasterio\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "\n",
    "with rasterio.open(os.path.join(BM.config[\"wksp\"], \"dem.tif\")) as src:\n",
    "    shape = src.shape\n",
    "    transform = src.transform\n",
    "\n",
    "class_lookup = BM.data[\"elevation\"][['beclabel','class_name']].drop_duplicates()\n",
    "\n",
    "results = FeatureCollection([\n",
    "        Feature(geometry=s, properties={\"beclabel\": BM.beclabel_lookup[v],                                         })\n",
    "        for i, (s, v)\n",
    "        in enumerate(\n",
    "            shapes(BM.data[\"becvalue_filtered\"], transform=src.transform))\n",
    "])\n",
    "\n",
    "df = BM.data[\"elevation\"]\n",
    "class_lookup = df[(df.class_name.str.upper() == 'PARKLAND') | (df.class_name.str.upper() == 'ALPINE')][['beclabel','class_name']].drop_duplicates()\n",
    "\n",
    "gdf = geopandas.GeoDataFrame.from_features(results)\n",
    "gdf2 = pd.merge(gdf, class_lookup, how=\"left\", on='beclabel')\n",
    "gdf.to_file(\"test_becvalue.shp\")\n",
    "gdf2.head()\n",
    "gdf2['descriptor'] = None\n",
    "gdf2.beclabel.str[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM.data[\"rulepolys\"].polygon_number.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/geopandas/geopandas/issues/369\n",
    "def multi2single(gpdf):\n",
    "    gpdf_singlepoly = gpdf[gpdf.geometry.type == 'Polygon']\n",
    "    gpdf_multipoly = gpdf[gpdf.geometry.type == 'MultiPolygon']\n",
    "\n",
    "    for i, row in gpdf_multipoly.iterrows():\n",
    "        Series_geometries = pd.Series(row.geometry)\n",
    "        df = pd.concat([gpd.GeoDataFrame(row, crs=gpdf_multipoly.crs).T]*len(Series_geometries), ignore_index=True)\n",
    "        df['geometry']  = Series_geometries\n",
    "        gpdf_singlepoly = pd.concat([gpdf_singlepoly, df])\n",
    "\n",
    "    gpdf_singlepoly.reset_index(inplace=True, drop=True)\n",
    "    return gpdf_singlepoly\n",
    "\n",
    "\n",
    "\n",
    "# try some spatial operations on alpine and parkland\n",
    "\n",
    "# first, simply dissolve\n",
    "#alpine = gdf2[gdf2.class_name.str.upper() == 'ALPINE']\n",
    "alpine_parkland = multi2single(gdf2.dissolve(by='class_name').reset_index())\n",
    "small_at = alpine_parkland[alpine_parkland.area < BM.config[\"parkland_removal_threshold\"]]\n",
    "small_at.plot()\n",
    "#gdf2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write output and load from disk\n",
    "BM.write()\n",
    "\n",
    "gdf = gpd.read_file(\n",
    "    os.path.join(BM.config[\"wksp\"], BM.config[\"out_file\"]), \n",
    "    layer=BM.config[\"out_layer\"]\n",
    ")\n",
    "\n",
    "# don't show 0 values\n",
    "gdf = gdf[gdf.becvalue > 0]\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize = (14,9))\n",
    "gdf.plot(\n",
    "    column='becvalue', \n",
    "    cmap='viridis', \n",
    "    ax=ax, \n",
    "    legend=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from becmodel import BECModel\n",
    "\n",
    "# load and process default (test) data\n",
    "BM = BECModel(config_file=\"/Users/snorris/projects/geobc/bec_modernization/test_projects/robson/robson_config.cfg\")\n",
    "BM.run()\n",
    "\n",
    "#BM.remove_parkland()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_poly(raster, layer):\n",
    "    with rasterio.open(os.path.join(BM.config[\"wksp\"], \"dem.tif\")) as src:\n",
    "        results = (\n",
    "            {\"properties\": {\"beclabel\": BM.beclabel_lookup[v]}, \"geometry\": s}\n",
    "            for i, (s, v) in enumerate(\n",
    "                shapes(raster, transform=src.transform)\n",
    "            )\n",
    "        )\n",
    "        with fiona.open(\n",
    "            os.path.join(BM.config[\"wksp\"], BM.config[\"out_file\"]),\n",
    "            \"w\",\n",
    "            layer=layer,\n",
    "            driver=\"GPKG\",\n",
    "            crs=src.crs,\n",
    "            schema={\"properties\": [(\"beclabel\", \"int\")], \"geometry\": \"Polygon\"},\n",
    "        ) as dst:\n",
    "            dst.writerecords(results)\n",
    "            \n",
    "def dump_image(image, out_prefix):\n",
    "    with rasterio.open(os.path.join(BM.config[\"wksp\"], \"dem.tif\")) as src:\n",
    "        with rasterio.open(\n",
    "            os.path.join(BM.config[\"wksp\"], out_prefix + \".tif\"),\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            dtype=rasterio.uint16,\n",
    "            count=1,\n",
    "            width=src.width,\n",
    "            height=src.height,\n",
    "            crs=src.crs,\n",
    "            transform=src.transform,\n",
    "        ) as dst:\n",
    "            dst.write(image.astype(np.uint16), indexes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract rule poly\n",
    "clip_poly = BM.data[\"rulepolys\"][BM.data[\"rulepolys\"].polygon_number == test_poly][[\"polygon_number\", \"geometry\"]]\n",
    "\n",
    "# buffer the rule poly\n",
    "clip_poly[\"geometry\"] = clip_poly.geometry.buffer(BM.config[\"expand_bounds\"])\n",
    "\n",
    "# find intersection of buffered rule poly and existing beczone polys\n",
    "clipped = gpd.overlay(BM.data[\"polys\"], clip_poly, how='intersection') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'AT  un'\n",
    "# dissolve\n",
    "a = multi2single(clipped[clipped.beclabel == label].dissolve(by=\"beclabel\").reset_index())\n",
    "# find areas less than threshold\n",
    "b = a[a.area < BM.config[\"parkland_removal_threshold\"]]\n",
    "# set these areas to parkland\n",
    "b.beclabel = parkland\n",
    "# update the master with these new codes by overlaying\n",
    "m = gpd.overlay(clipped, b, how='union') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the zones effected by the parkland_removal_threshold\n",
    "\n",
    "# extract areas to consider & dissolve \n",
    "#for label in [alpine, parkland, woodland]:\n",
    "    # extract and dissolve\n",
    "    a = clipped[clipped.beclabel == label]\n",
    "    to_consider = multi2single(clipped.dropna(subset=['descriptor']).dissolve(by=\"descriptor\").reset_index())\n",
    "\n",
    "# find Alpine areas < threshold\n",
    "small_alpine = to_consider[(to_consider.area < BM.config[\"parkland_removal_threshold\"]) & (to_consider.descriptor == 'ALPINE')]\n",
    "\n",
    "# extract parkland\n",
    "parkland = to_consider[to_consider.descriptor == 'PARKLAND']\n",
    "\n",
    "# find parkland adjacent to the small alpine areas via spatial join\n",
    "alpine_parkland = gpd.sjoin(small_alpine, parkland, how=\"inner\", op='intersects')\n",
    "\n",
    "# dissolve on beclabel before applying the update\n",
    "to_insert = multi2single(alpine_parkland.dissolve(by=\"beclabel_right\").reset_index())\n",
    "\n",
    "# tidy \n",
    "tidied = to_insert[[\"beclabel_right\", \"geometry\"]].rename(columns={'beclabel_right': 'beclabel_parkland'})\n",
    "\n",
    "# update the clipped data with the new beclabels\n",
    "c = gpd.overlay(clipped, tidied, how='union') \n",
    "c.beclabel = np.where(c[\"beclabel_parkland\"].notna(), c[\"beclabel_parkland\"], c[\"beclabel\"])\n",
    "\n",
    "# dissolve\n",
    "d = multi2single(c.dissolve(by=\"beclabel\").reset_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
